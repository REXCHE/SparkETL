
# Chapter 7 -> Spark ETL with Lakehouse | Delta Lake

Task to do 
1. Read data from MySQL server into Spark
2. Create HIVE temp view from data frame
3. Load filtered data into Delta format (create initial table)
4. Load filtered data again into Delta format into same table 
5. Read Delta tables using Spark data frame
6. Create Temp HIVE of delta tables
7. Write query to read data and also explore versions

Solution Notebook:<br/>
[Spark Notebook](chapter7.ipynb)

Blog with Explaination: <br/>
https://developershome.blog/2023/03/18/spark-etl-chapter-6-with-apis/

YouTube video with Explanation: <br/>
https://www.youtube.com/watch?v=eL1xIjranhg

Meduim Blog Channel: <br/>
https://medium.com/@developershome
