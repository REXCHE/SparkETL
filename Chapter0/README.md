
# Chapter 0 -> Spark ETL with files (CSV | JSON | Parquet | Text | Spark Dataframe)

Task to do 
1. Read CSV file and write into dataframe
2. Read JSON file and write into dataframe 
3. Read Parquet file and write into dataframe
4. Read text file and write into dataframe
5. Create temp table for all 
6. Create JSON file from CSV dataframe
7. Create CSV file from Parquet dataframe
8. Create parquet file from JSON dataframe
9. Create orc file from JSON dataframe

Reference Data:<br/>
https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page

Solution Notebook:<br/>
[Spark Notebook](chapter0.ipynb)

Blog with Explaination: 
https://medium.com/@fylfotbeta/spark-etl-chapter-0-with-files-csv-json-parquet-orc-87359909c568

https://developershome.blog/2023/03/02/spark-etl-chapter-0-with-files-csv-json-parquet-orc/

YouTube video with Explanation:
https://youtu.be/fL_DpgyU040