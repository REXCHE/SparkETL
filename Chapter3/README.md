
# Chapter 3 -> Spark ETL with Azure (Blob | ADLS)

Task to do 
1. Install required spark libraries
2. Create connection with Azure Blob storage
3. Read data from blob and store into dataframe
4. Transform data
5. write data into parquet file 
6. write data into JSON file

Reference:<br/>
https://learn.microsoft.com/en-us/azure/open-datasets/dataset-catalog

Solution Notebook:<br/>
[Spark Notebook](chapter3.ipynb)

Blog with Explaination: 

YouTube video with Explanation:
