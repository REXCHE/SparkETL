
# Chapter 6 -> Spark ETL with APIs

Task to do 
1. Call API and load data into Dataframe 
2. Create temp table or view and analyse data 
3. Filter data and store into CSV format on file server
4. Filter data and store into JSON format

Reference:<br/>
https://api.publicapis.org/entries

Solution Notebook:<br/>
[Spark Notebook](chapter6.ipynb)

Blog with Explaination: <br/>
https://developershome.blog/2023/03/18/spark-etl-chapter-6-with-apis/

YouTube video with Explanation:
https://www.youtube.com/watch?v=eL1xIjranhg
