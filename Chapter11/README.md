
# Chapter 9 -> Spark ETL with Lakehouse | Apache Iceberg

Task to do 
1. Read data from MySQL server into Spark
2. Create HIVE temp view from data frame
3. Load filtered data into Iceberg format (create initial table)
4. Load filtered data again into Iceberg format into same table 
5. Read Iceberg tables using Spark data frame
6. Create Temp HIVE of Iceberg tables
7. Write query to read data and also explore versions

Solution Notebook:<br/>
[Spark Notebook](chapter9.ipynb)

Blog with Explaination: <br/>
https://developershome.blog/2023/03/21/spark-etl-chapter-9-with-lakehouse-apache-iceberg/

YouTube video with Explanation: <br/>
https://www.youtube.com/watch?v=eL1xIjranhg

Meduim Blog Channel: <br/>
https://medium.com/@developershome
